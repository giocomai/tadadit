---
title: "kremlin.ru_en"
description: "All items published on the English language version of the Kremlin's website"
author: Giorgio Comai
date: 2023-03-13
last-modified: 2023-06-28
categories: [dataset, Russian institutions, English language]
---

{{< include ./../_early_disclaimer.qmd >}}

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.width = 8,
                      fig.height = 4.5)

library("ggplot2")
library("dplyr", warn.conflicts = FALSE)

ggplot2::theme_set(new = theme_minimal(base_family = "Roboto Condensed"))

```

```{r}

library("castarter")

cas_set_options(
  base_folder = fs::path(fs::path_home_r(), 
                         "R",
                         "castarter_tadadit"),
  project = "Russian institutions",
  website = "kremlin.ru_en" 
)

corpus_df <- cas_read_db_contents_data() %>% 
  dplyr::collect()

max_date <- max(as.Date(corpus_df$date))

min_date <- min(as.Date(corpus_df$date))

total_items <- nrow(corpus_df)


```

## Check for duplicates

The dataset has originally been generated by parsing all index pages for the following categories available on the Kremlin's website:

```{r}
# cas_read_db_index() |> 
#   dplyr::group_by(index_group) |> 
#   dplyr::count() |> 
#   dplyr::arrange(dplyr::desc(n)) |> 
#   dplyr::collect() |> 
#   knitr::kable()

cas_read_db_index() |> 
  dplyr::distinct(index_group) |> 
  dplyr::collect() |> 
  knitr::kable()

```

In total, the corpus thus generated has `r scales::number(nrow(corpus_df))` items. It appears, however, that starting with 2008 items that are included in more than one category are published with a separate url. These are items published on the same date, with the same title, and exactly (or almost exactly) the same text, yet would still be included each time they appear as they have a separate url. Here are a few examples:

```{r}
corpus_df |> 
  dplyr::mutate(internal_id = stringr::str_extract(string = url,
                                                   pattern = "[[:digit:]]+$")) |> 
  dplyr::group_by(internal_id) |> 
  dplyr::filter(dplyr::n()>1) |>
  dplyr::ungroup() |> 
  dplyr::arrange(date, internal_id) |> 
  dplyr::select(date, url, title, internal_id) |> 
  dplyr::slice_head(n = 6) |> #|> View()
  knitr::kable()
```

Luckily, it is easy to notice that such duplicated articles share the same internal id (the numeric part at the end of the url is the same).

For analytical purposes, it makes sense to drop such duplicated items.

```{r}
corpus_deduplicated_df <- corpus_df |> 
    dplyr::mutate(internal_id = stringr::str_extract(string = url,
                                                   pattern = "[[:digit:]]+$")) |> 
  dplyr::distinct(internal_id, .keep_all = TRUE)

corpus_df <- corpus_deduplicated_df
```

Once these duplicated items are removed, the total number of items is effectively `r scales::number(nrow(corpus_deduplicated_df))`. These are the ones that are included in the published dataset and used in further analyses.

```{r eval = FALSE}
corpus_df |> 
  dplyr::group_by(date, text) |> 
  dplyr::add_count() |> 
  dplyr::ungroup() |> 
  dplyr::filter(n>1) |> 
  dplyr::arrange(date, id) 
```

```{r piggyback, eval = FALSE}

castarter::cas_write_corpus(corpus = corpus_df,
                            partition = "year")

data_path <- fs::path(fs::path_home_r(), 
                      "R",
                      "castarter_tadadit_data")

fs::dir_create(data_path)
release_file <- fs::path(data_path, 
                         "kremlin.ru_en.csv.gz")

corpus_df %>% 
  readr::write_csv(file = release_file)

data_df <- readr::read_csv(release_file)

max_date <- max(data_df$date)

min_date <- min(data_df$date)

total_items <- nrow(data_df)




body_text <- stringr::str_c("**Dataset name**: kremlin.ru_en",
                            "**Dataset description**: all items published on the English language version of the Kremlin's website",
                            paste("**Start date**:", min_date),
                            paste("**End date**:", max_date),
                            paste("**Total items**:", total_items),
                            paste("**Available columns**:", colnames(data_df) %>% 
                                    stringr::str_c(collapse = "; ")),
                            sep = "\n")

body_text

# piggyback::pb_new_release(repo = "giocomai/tadadit",
#                tag = "kremlin.ru_en",
#                body = body_text)

piggyback::pb_upload(file = release_file, 
          repo = "giocomai/tadadit", 
          tag = "kremlin.ru_en")
```

```{r}
max_date <- max(as.Date(corpus_df$date))

min_date <- min(as.Date(corpus_df$date))

total_items <- nrow(corpus_df)


```

## Summary statistics

```{r results='asis'}
body_text <- stringr::str_c(
  "**Dataset name**: kremlin.ru_en",
  "**Dataset description**: all items published on the English language version of the Kremlin's website",
  paste("**Start date**:", min_date),
  paste("**End date**:", max_date),
  paste("**Total items**:", scales::number(total_items)),
  paste("**Available columns**:", colnames(corpus_df) %>% 
          stringr::str_c(collapse = "; ")),
  paste("**License**:", "[Creative Commons Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/deed.ru)"),
  paste("**Link for download**: [kremlin.ru_en](https://github.com/giocomai/tadadit/releases/tag/kremlin.ru_en)"),
  sep = "\n\n")

cat(body_text)
```

```{r}
#| column: body
#| fig-width: 8
#| fig-height: 4.5
corpus_df |>
  mutate(year = lubridate::year(date)) |> 
  count(year) |> 
  ggplot(mapping = aes(x = year, y = n)) +
  geom_col() +
  scale_y_continuous(name = "", labels = scales::number) +
  scale_x_continuous(name = "", breaks = scales::pretty_breaks(n = 10)) +
  labs(
    title = "Number of items per year published on the English-language version of Kremlin.ru",
    subtitle = stringr::str_c(
      "Based on ",
      scales::number(nrow(corpus_df)),
      " items published between ",
      format.Date(x = min(corpus_df$date), "%d %B %Y"), 
      " and ",
      format.Date(x = max(corpus_df$date), "%d %B %Y")),
    caption = "Source: Giorgio Comai / tadadit.xyz"
  )
```

```{r}
words_per_day_df <- corpus_df |> 
  cas_count_total_words() |> 
  mutate(date = lubridate::as_date(date),
         pattern = "total words")

words_per_day_df |> 
  cas_summarise(period = "year", auto_convert = TRUE) |>
  rename(year = date) |> 
  ggplot(mapping = aes(x = year, y = n)) +
  geom_col() +
  scale_y_continuous(name = "", labels = scales::number) +
  scale_x_continuous(name = "", breaks = scales::pretty_breaks(n = 10)) +
  labs(title = "Number of words per year published on the the English-language version of Kremlin.ru",
       subtitle = stringr::str_c("Based on ",
                                 scales::number(nrow(corpus_df)),
                                 " items published between ",
                                 format.Date(x = min(corpus_df$date), "%d %B %Y"), 
                                 " and ",
                                 format.Date(x = max(corpus_df$date), "%d %B %Y")),
       caption = "Source: Giorgio Comai / tadadit.xyz")
```
