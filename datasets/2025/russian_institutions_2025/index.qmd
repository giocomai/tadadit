---
title: "Russian state institutions 2024"
listing:
  sort: "title asc"
  type: table
  image-align: right
  categories: true
  sort-ui: true
  filter-ui: true
  feed: true  
  fields: [title, description, categories]
editor: source
---

This is a collection of full-text datasets based on contents extracted from the websites of Russian institutions.

This is a stable release.

- all datasets do not include materials published after 31 December 2023
- download urls and links to metadata pages are expected to remain available at their current location; updates with new contents may be announced here, but will be published separately; any quality adjustment introduced after final publication will be documented
- a formal release in an established repository is forthcoming - relevant links will be added here
- context and use cases are described in a dedicated book chapter:

> Comai, Giorgio (2025, forthcoming), "Text-mining on-line sources from Russia openly", in *Autocracy, Influence, War: Russian Propaganda Today*, edited by Paul Goode

The name of each corpus is composed of the bare domain name, a two letter code of the main language of the contents, and the year of release of the dataset, separated by an underscore, e.g. `kremlin.ru_ru_2024`.

```{r setup, echo=FALSE, eval = TRUE, message=FALSE, warning=FALSE}
library("piggyback")
options(piggyback.verbose = FALSE)
base_folder <- fs::dir_create(fs::path(fs::path_home_r(), "R", "ru_institutions_2024"))

get_corpus <- function(corpus_name) {
  # pb_download(dest = base_folder, 
  #           repo = "giocomai/tadadit",
  #           tag = corpus_name, 
  #           file = stringr::str_c(corpus_name, ".csv.gz", collapse = ""))
  invisible(fs::path(base_folder, stringr::str_c(corpus_name, ".csv.gz", collapse = "")))
}

```

## Dataset format

Datasets are published as compressed csv files (.csv.gz), as well as in .ods format. 

In line with the [`tif` standard](https://docs.ropensci.org/tif/), each corpus has a few standard columns, as well as additional metadata depending on availability:

- the first column is always `doc_id`, and is composed of the bare corpus name (based on base domain of the source and language) and a numeric id, separated by an underscore. For the Russian version of Kremlin's website, such id would look as follows: `kremlin.ru_ru_12345` (where 12345 is the numeric id associated with the given item). Numeric identifiers have no inherent meaning; their order may be substantially meaningless. If the original source website includes in the url a unique numeric id, this is maintained in the doc_id; otherwise an id is given at database creation (and the order numbering may depend on the way the extraction process was implemented). This format allows to combine datasets, ensuring `doc_id` is still unique.
- the second column is always `text`: this is the main text included in the source page
- the third colums is always `title`
- the fourth colums is always `date`
- other time-related fields, such as `time` and `datetime`, may follow if available (time and date refer to the original publication timezone; in this release, this is always Moscow's time)
- additional columns include fields and metadata, depending on availability of contents: this may include substantive text contents (e.g. a separate `lede` or `description` field), categories, tags, location, author, additional identifiers, etc.
- finally, `url` is always the last column

`doc_id` and `url` are conceptually unique and always present. In all of these datasets, also `date` is always present. All other fields may be missing or empty for some of the items (e.g. there may be items with title, but no text, or vice-versa). See the documentation accompanying each dataset for more details. 

## License

Details about licensing are includeded along with the documentation of each corpus. The specifics vary slightly, but all of the source websites used to create this collection explicitly allowed for re-publication of contents a under a Creative Commons (CC-BY) license or similar. [To the extent that it is possible](https://joinup.ec.europa.eu/licence/compatibility-check/ODC-By-1.0/CC-BY-4.0), the datasets themselves are also distributed by its creator, Giorgio Comai, under the Open Data Commons Attribution license (ODC-BY).

## Summary statistics

*Click on the corpus name for more information and download links*

```{r available_corpora, echo=FALSE, message=FALSE, warning=FALSE}
#| column: screen

available_df <- tibble::tribble(
  ~institution, ~corpus_name, 
  "Russia's president", "kremlin.ru_en_2024", 
  "Russia's president", "kremlin.ru_ru_2024",
  "Russia's MFA", "mid.ru_ru_2024",
  "Russia's MFA", "mid.ru_en_2024",
  "Russia's government", "government.ru_ru_2024",
  "Russia's government (archived version)", "archive.government.ru_ru_2024",
  "Russia's prime minister (archived version)", "archive.premier.gov.ru_ru_2024",
  "Russia's Duma", "duma.gov.ru_ru_2024",
  "Russia's Duma (transcripts)", "transcript.duma.gov.ru_ru_2024"
  
  )

summary_stats_df <- purrr::map(
  .x = purrr::transpose(available_df),
  .f = \(x) {

    corpus_df <- invisible(readr::read_csv(file = get_corpus(corpus_name = x[["corpus_name"]])))
    
    earliest <- min(corpus_df[["date"]])
    
    total <- nrow(corpus_df)
    
    tibble::tibble(
      institution = x[["institution"]],
      website = stringr::str_remove(string = x[["corpus_name"]],
                                   pattern = "_[[:alpha:]]{2}_[[:digit:]]{4}$"), 
                   language = stringr::str_remove(string = x[["corpus_name"]],
                                   pattern = "_[[:digit:]]{4}$") |> 
      stringr::str_extract(pattern = "[[:alpha:]]{2}$"), 
      `corpus name` = stringr::str_c("[", x[["corpus_name"]], "](", x[["corpus_name"]], ")", collapse = ""),
      `start date` = min(corpus_df[["date"]] |> lubridate::as_date()), 
      `end date` = max(corpus_df[["date"]] |> lubridate::as_date()), 
      n_items = nrow(corpus_df)
      )
  }) |> 
  purrr::list_rbind()

readr::write_csv(x = summary_stats_df, file = "ru_institutions_2024_summary_stats.csv")

summary_stats_df |> 
  knitr::kable(format.args = list(big.mark = " "),
               escape = FALSE)
```

## List of available datasets