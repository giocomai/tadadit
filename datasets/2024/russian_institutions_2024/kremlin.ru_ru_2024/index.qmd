---
title: "kremlin.ru_ru_2024"
description: "Corpus based on Russia's president website (in Russian, 1999-2023)"
author: Giorgio Comai
date: 2024-02-24
last-modified: 2024-03-25
categories: [dataset, Russian institutions, Russian language]
editor: source
---


```{r setup, echo = FALSE, message=FALSE, warning=FALSE, results='asis'}
website_name <- "kremlin.ru_ru"
description_string_01 <- "all news items published on"
description_string_02 <- "the Russian-language version of Kremlin.ru"
license_string <- "[Creative Commons Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/deed.ru)"

source(fs::path("..", "dataset_setup_2024.R"))


download_callout()

```


## Scope of this dataset

This textual dataset is based on [kremlin.ru](http://kremlin.ru/), i.e. the Russian-language version of the official website of the president of the Russian Federation. It includes only its main sections with news and updates; it does not include other sections of the website such as legal documents, the Constitution, etc. 

This dataset includes contents published between 31 December 1999 and 31 December 2023, under two Russian presidents: Vladimir Putin and Dmitri Medvedev. 

## Summary statistics

```{r summary_stats, results='asis'}
summary_stats_text()
```


```{r items_per_year}
items_per_year()
```

```{r words_per_year}
words_per_year()
```

```{r missing_table}
missing_table()
```

```{r missing_graph}
missing_graph()
```


## Narrative explanation of how this textual dataset was built

Kremlin.ru publishes all of its news items in one ore more of the following sections:

- [transcripts](http://kremlin.ru/events/president/transcripts)
- [Presidential Executive Office](http://kremlin.ru/events/administration)
- [State Council](http://kremlin.ru/events/state-council)
- [Security Council](http://kremlin.ru/events/security-council)
- [Commissions and Councils](http://kremlin.ru/events/councils)
- [news](http://kremlin.ru/events/president/news)

This dataset has been generated by parsing each of these sections, similarly to what would be accomplished by insistently clicking on the "show more" link at the bottom of the relevant index pages until the oldest post has been reached.

Some items are posted in more than one section with different urls; they however keep the same internal id: a series of up to 5 digits included at the end of each url. For example, the article "Meeting with permanent members of the Security Council" has been posted on 4 February 2011 at both of the following urls:

- http://kremlin.ru/events/president/news/10235
- http://kremlin.ru/events/security-council/10235

In order to prevent duplication of contents, only one of these articles is preserved in the final dataset; for consistency, only the first match, according to the order in which sections are listed above, is kept. This allows to see easily which posts are defined as "transcripts" and gives precedence to more specific sections (the generic "news" is used only if the given item was not posted in previous sections). This choice should be substantively irrelevant for most use cases, as all sections are anyway included in a separate field. 

## License information

At the time contents were retrieved, the footer of kremlin.ru as well as the dedicated [copyright page](http://kremlin.ru/about/copyrights) make clear that:

> "all materials published on this website are available with the following license "[Creative Commons Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/deed.ru)"

This license gives the right to “copy and redistribute the material in any medium or format”, and to “remix, transform, and build upon the material for any purpose, even commercially”, as long as appropriate credit is given to the source and the license is included.

The contents of this dataset - “kremlin.ru_ru” - are distributed within the remits of this license. To the extent that it is possible, the dataset itself is also distributed by its creator, Giorgio Comai, with the same CC-BY license, as well as under the Open Data Commons Attribution license (ODC-BY).




```{r}
corpus_original_df <- cas_read_db_contents_data() |> 
  dplyr::collect() 

corpus_df <- corpus_original_df
```


## Dataset cleaning and reordering

The following steps are conducted on the original dataset before exporting:

- ensure all items have a date
- ensure no post following the cut-off date (`r end_date`) is included
- ensure no posts with the numerical component of the url (`url_id`) are included
- introduce a `doc_id` column (composed of the website base url, the language of the dataset, and the `url_id`) and set this as the first column of the dataset


```{r cleaning}
corpus_df <- corpus_original_df

corpus_pre_df <- corpus_df 

## ensure dates always present
corpus_df <- corpus_df |> 
  dplyr::filter(is.na(date)==FALSE) 
  
check <- assertthat::assert_that(nrow(corpus_original_df)==nrow(corpus_df), 
                        msg = "rows dropped due to missing dates")

## close dataset at end date
corpus_df <- corpus_df |> 
  dplyr::filter(date<=end_date) 


## deduplicate consistently by section order

section_order_v <- c("http://kremlin.ru/events/president/transcripts/",
  "http://kremlin.ru/events/administration/",
  "http://kremlin.ru/events/state-council/",
  "http://kremlin.ru/events/security-council/", 
  "http://kremlin.ru/events/councils/",
  "http://kremlin.ru/events/president/news/")

corpus_pre_df <- corpus_df 

corpus_df <- tibble::tibble(section_order = section_order_v) |> 
  dplyr::left_join(corpus_df |> 
  dplyr::mutate(section_order = stringr::str_remove(url, "[[:digit:]]+")),
  by = "section_order") 
 
check <- assertthat::assert_that(nrow(corpus_pre_df)==nrow(corpus_df),
                        msg = "rows dropped when reordering by section")


corpus_df <- corpus_df |>
  dplyr::distinct(internal_id, .keep_all = TRUE) |> 
  dplyr::arrange(date, internal_id) |> 
  dplyr::select(-section_order)


check <- assertthat::assert_that(0 == corpus_df |> 
                          dplyr::group_by(internal_id) |> 
                          dplyr::count() |> 
                          dplyr::ungroup() |> 
                          dplyr::filter(n>1) |> 
                          nrow(),
                        msg = "duplicated items still present")



corpus_df <- corpus_df |> 
  dplyr::select(-id) |> 
  dplyr::rowwise() |> 
  dplyr::mutate(doc_id = stringr::str_c(website_name, "_", internal_id)) |> 
  dplyr::ungroup() |> 
  dplyr::rename(url_id = internal_id) |> 
  dplyr::relocate(doc_id, text, title, date, time, datetime) |> 
  dplyr::relocate(url_id, url, .after = dplyr::last_col())

check <- assertthat::assert_that(nrow(corpus_df) == nrow(corpus_df |> dplyr::distinct(doc_id)),
                                 msg = "duplicated doc_id")
```



```{r piggyback, eval = FALSE}
source(fs::path("..", "piggyback_corpus.R"))
```

## Useful links

- the English-language version of this corpus: [kremlin.ru_en_2024](https://tadadit.xyz/datasets/russian_institutions_2024/kremlin.ru_en_2024/)
- a detailed walkthrough of the technicalities involved in creating this corpus: [Extracting textual contents from the Kremlin’s website with castarter](https://tadadit.xyz/tutorials/2023-02-kremlin_ru_en_extract/)
- an blog post using a previous version of this dataset: [Russophobia in Russian official statements and media](https://tadadit.xyz/posts/2023-09-russophobia/)



