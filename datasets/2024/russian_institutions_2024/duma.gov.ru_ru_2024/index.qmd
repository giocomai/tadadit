---
title: "duma.gov.ru_ru_2024"
description: "Corpus based on the Russia's Duma website (in Russian, 2006-2023)"
author: Giorgio Comai
date: 2024-08-23
last-modified: 2024-08-23
categories: ["dataset", "Russian institutions", "Russian government", "Russian language"]
editor: source
---

```{r setup, echo = FALSE, message=FALSE, warning=FALSE, results='asis'}
website_name <- "duma.gov.ru_ru"
description_string_01 <- "all news items published on"
description_string_02 <- "duma.gov.ru"
license_string <- "[Creative Commons Attribution 3.0 International](http://creativecommons.org/licenses/by/3.0/)"

source(fs::path("..", "dataset_setup_2024.R"))


download_callout()

```

## Scope of this corpus

This corpus is based on all contents published in the "news" section of the website [duma.gov.ru](http://duma.gov.ru/) as it was available online in early 2024.


## Summary statistics

```{r summary_stats, results='asis'}
summary_stats_text()
```


```{r items_per_year}
items_per_year()
```

```{r words_per_year}
words_per_year()
```

```{r missing_table}
missing_table()
```

```{r missing_graph}
missing_graph()
```


## Narrative explanation of how this corpus has been created

This corpus has been built based on index pages of the ["news" section of the website](http://duma.gov.ru/news/), parsing older posts as they would appear when clicking on the "Загрузить предыдущие материалы" button.

Text and metadata have been extracted from the resulting pages, relying on the well structured format of the news pages, presenting each element in a dedicated element:

- the title is always included in a `<h1>` element of class `article__title`
- the date and datetime are retrieved from `time` container, `datetime` attribute, `datePublished` item proposition
- the lead is included (when available) in a `<div>` element of class `article__lead`
- the section is included in a `<a>` element of class `article__caption`
- the main text is always included in a `<div>` element of class `article__content`

### Data cleaning

All items published on the website include a date of publication. The `lead` is quite often missing, as appears from the summary information above. There are, in total, 16 items with an empty text field; 9 of them have also an empty `lead` field. This is not due to data retrieval issues, but rather, to the original contents themselves, which often expect the title - perhaps accompanied by a picture - to be self-explanatory. See [an example](http://duma.gov.ru/news/54127/).

## License information

The [about page of the website](http://duma.gov.ru/about/info/) includes a section "On the use of information" ("Об использовании информации"), which clarifies the permissive conditions for re-publishing contents used on the website. Even if it does not include reference to specific license, it unambiguously states that contents can be published anywhere, without any sort of limitation, with the only condition being that a link the original source must be included. 

> Все материалы официального сайта Государственной Думы Федерального Собрания Российской Федерации могут быть воспроизведены в любых средствах массовой информации, на серверах сети Интернет или на любых иных носителях без каких‑либо ограничений по объему и срокам публикации.
> Это разрешение в равной степени распространяется на газеты, журналы, радиостанции, телеканалы, сайты и страницы сети Интернет. Единственным условием перепечатки и ретрансляции является ссылка на первоисточник. Никакого предварительного согласия на перепечатку со стороны Аппарата Государственной Думы не требуется.

The contents of this dataset - “duma.gov.ru_ru” - are distributed within the remits of this license. To the extent that it is possible, the dataset itself is also distributed by its creator, Giorgio Comai under the Open Data Commons Attribution license (ODC-BY).



```{r corpus_original_df, eval = FALSE}
corpus_original_df <- cas_read_db_contents_data() |> 
  dplyr::collect() 

corpus_df <- corpus_original_df

# corpus_df |> dplyr::filter(text=="") |> View()
```



```{r cleaning, eval = FALSE}
corpus_df <- corpus_original_df

corpus_pre_df <- corpus_df 

## ensure dates always present
corpus_df <- corpus_df |> 
  dplyr::filter(is.na(date)==FALSE) 
  
check <- assertthat::assert_that(nrow(corpus_original_df)==nrow(corpus_df), 
                         msg = "rows dropped due to missing dates")

## close dataset at end date
corpus_df <- corpus_df |> 
  dplyr::filter(date<=end_date) 


corpus_df <- corpus_df |> 
  dplyr::select(-id) |> 
  dplyr::rowwise() |> 
  dplyr::mutate(doc_id = stringr::str_c(website_name, "_", internal_id)) |> 
  dplyr::ungroup() |> 
  dplyr::relocate(doc_id, text, title, date, datetime) |> 
  dplyr::relocate(url, .after = dplyr::last_col()) |> 
  dplyr::arrange(date, internal_id)

```


```{r piggyback, eval = FALSE}
source(fs::path("..", "piggyback_corpus.R"))
```


