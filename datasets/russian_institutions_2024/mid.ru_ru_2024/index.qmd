---
title: "mid.ru_ru_2024"
description: "Russia's MFA (in Russian, 2003-2023)"
author: Giorgio Comai
date: 2024-03-20
last-modified: 2024-03-20
categories: [dataset, Russian institutions, Russian MFA, Russian language]
editor: source
---


```{r setup, echo = FALSE}
source(fs::path("..", "dataset_setup_2024.R"))

cas_set_options(
  base_folder = fs::path(fs::path_home_r(), 
                         "R",
                         "castarter_2024"),
  project = "Russian institutions",
  website = "mid.ru_ru" 
)

corpus_original_df <- cas_read_db_contents_data() |> 
  dplyr::collect()

corpus_df <- corpus_original_df

website_name <- cas_get_options()[["website"]]
corpus_name <- stringr::str_c(website_name, "_2024")
```

## Scope of this dataset

[TODO]

## Narrative explanation of how this textual dataset was built

[TODO]

## Metadata

[TODO]

## License information

At the time contents were retrieved, the [page on the conditions for the use of website contents](https://mid.ru/ru/ob_ispolzovanii_informatsii_sayta/) makes clear that contents can be used for research purposes and can be re-published, as long as reference is always made to the website of the MFA.

> Материалы сайта МИД России являются общедоступными и открытыми для использования в некоммерческих (личных, ознакомительных, образовательных, исследовательских и аналогичных) целях.

> Их перепечатка, а также цитирование в СМИ допускается только при условии ссылки на сайт МИД России как источник информации

No specific license is however mentioned.

The contents of this dataset - “mid.ru_ru” - are distributed within the remits of this license. To the extent that it is possible, the dataset itself is also distributed by its creator, Giorgio Comai, at the same conditions, as well as under the Open Data Commons Attribution license (ODC-BY).


## Dataset cleaning steps


[TODO]


```{r cleaning}
corpus_df <- corpus_original_df

corpus_pre_df <- corpus_df 

## ensure dates always present
corpus_df <- corpus_df |> 
  dplyr::filter(is.na(date)==FALSE) 
  
# check <- assertthat::assert_that(nrow(corpus_original_df)==nrow(corpus_df), 
#                         msg = "rows dropped due to missing dates")

## close dataset at end date
corpus_df <- corpus_df |> 
  dplyr::filter(date<=end_date) 


corpus_df <- corpus_df |> 
  dplyr::select(-id) |> 
  dplyr::rowwise() |> 
  dplyr::mutate(doc_id = stringr::str_c(website_name, "_", url_id)) |> 
  dplyr::ungroup() |> 
  dplyr::relocate(doc_id, text, date, datetime, title, internal_id, url_id) |> 
  dplyr::arrange(datetime, internal_id)

```



## Summary statistics

```{r results='asis'}
body_text <- stringr::str_c(
  stringr::str_c("**Dataset name**: ", website_name),
  "**Dataset description**: all items published on the Russian-language version of the website of Russia's MFA",
  paste("**Start date**:", min(corpus_df$date)),
  paste("**End date**:", max(corpus_df$date)),
  paste("**Total items**:", scales::number(nrow(corpus_df))),
  paste("**Available columns**:", colnames(corpus_df) %>% 
          stringr::str_c(collapse = "; ")),
  paste("**License**:", "re-publishing of contents allowed by website's terms of use, but no clear license given"),
  stringr::str_c("**Link for download**: [", corpus_name, "](https://github.com/giocomai/tadadit/releases/tag/", corpus_name, ")"),
  sep = "\n\n")

cat(body_text)

```

```{r}
#| column: body
#| fig-width: 8
#| fig-height: 4.5
corpus_df |>
  mutate(year = lubridate::year(date)) |> 
  count(year) |> 
  ggplot(mapping = aes(x = year, y = n)) +
  geom_col() +
  scale_y_continuous(name = "", labels = scales::number) +
  scale_x_continuous(name = "", breaks = scales::pretty_breaks(n = 10)) +
  labs(
    title = "Number of items per year published on the Russian-language version of mid.ru",
    subtitle = stringr::str_c(
      "Based on ",
      scales::number(nrow(corpus_df)),
      " items published between ",
      format.Date(x = min(corpus_df$date), "%d %B %Y"), 
      " and ",
      format.Date(x = max(corpus_df$date), "%d %B %Y")),
    caption = "Source: Giorgio Comai / tadadit.xyz"
  )
```

```{r}
words_per_day_df <- corpus_df |> 
  cas_count_total_words() |> 
  mutate(date = lubridate::as_date(date),
         pattern = "total words")

words_per_day_df |> 
  cas_summarise(period = "year", auto_convert = TRUE) |>
  rename(year = date) |> 
  ggplot(mapping = aes(x = year, y = n)) +
  geom_col() +
  scale_y_continuous(name = "", labels = scales::number) +
  scale_x_continuous(name = "", breaks = scales::pretty_breaks(n = 10)) +
  labs(title = "Number of words per year published on the Russian-language version of mid.ru",
       subtitle = stringr::str_c("Based on ",
                                 scales::number(nrow(corpus_df)),
                                 " items published between ",
                                 format.Date(x = min(corpus_df$date), "%d %B %Y"), 
                                 " and ",
                                 format.Date(x = max(corpus_df$date), "%d %B %Y")),
       caption = "Source: Giorgio Comai / tadadit.xyz")
```



```{r piggyback, eval = FALSE}

corpus_path <- fs::path(fs::path_home_r(), 
                      "R",
                      "castarter_2024",
                      "corpora")

fs::dir_create(corpus_path)

release_file <- fs::path(corpus_path, 
                         stringr::str_c(corpus_name, ".csv.gz"))

corpus_df |> 
  readr::write_csv(file = release_file)


piggyback::pb_release_create(repo = "giocomai/tadadit",
                             tag = corpus_name,
                             body = body_text)

piggyback::pb_upload(file = release_file,
                     repo = "giocomai/tadadit",
                     tag = corpus_name)

ods_file <- fs::path(corpus_path, 
                         stringr::str_c(path = corpus_name, ".ods"))
                      
readODS::write_ods(x = corpus_df, path = ods_file)

piggyback::pb_upload(file = ods_file,
          repo = "giocomai/tadadit",
          tag = corpus_name)
```


