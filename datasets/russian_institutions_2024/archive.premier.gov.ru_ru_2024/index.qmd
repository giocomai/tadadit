---
title: "archive.premier.gov.ru_ru_2024"
description: "Archived version of Russia's prime minister website (Russian version, 2008-2013)"
author: Giorgio Comai
date: 2024-03-20
last-modified: 2024-03-20
categories: [dataset, Russian institutions, Russian Prime Minister, Russian language]
editor: source
---


```{r eval=TRUE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      eval = FALSE,
                      warning = FALSE)
```


```{r setup, echo = FALSE}
source(fs::path("..", "dataset_setup_2024.R"))

cas_set_options(
  base_folder = fs::path(fs::path_home_r(), 
                         "R",
                         "castarter_2024"),
  project = "Russian institutions",
  website = "archive.premier.gov.ru_ru" 
)

corpus_original_df <- cas_read_db_contents_data() |> 
  dplyr::collect()

corpus_df <- corpus_original_df

website_name <- cas_get_options()[["website"]]
corpus_name <- stringr::str_c(website_name, "_2024")
```

## Scope of this dataset

[TODO]

## Narrative explanation of how this textual dataset was built

[TODO]

## Metadata

[TODO]

## License information

At the time contents were retrieved, the footer of the website makes clear that all contents available are published with a Creative Commons Attribution 3.0 license:

> [Все материалы сайта доступны по лицензии: Creative Commons Attribution 3.0 Непортированная](http://creativecommons.org/licenses/by/3.0/)"

Additional context in the [about page](http://archive.premier.gov.ru/about.html) reiterates that there are not other limitations on re-publication of contents:

> "Все материалы сайта Председателя Правительства Российской Федерации могут быть воспроизведены в любых средствах массовой информации, на серверах сети Интернет или на любых иных носителях без каких-либо ограничений по объему и срокам публикации."

The contents of this dataset - “archive.premier.gov.ru_ru” - are distributed within the remits of this license. To the extent that it is possible, the dataset itself is also distributed by its creator, Giorgio Comai, with the same CC-BY license, as well as under the Open Data Commons Attribution license (ODC-BY).


## Dataset cleaning steps

### Drop duplicates

Some items have been posted on the same date, with the same title, and mostly with exactly or almost exactly the same text under different sections of the websites. In such cases (250 in total), the one categorised as "transcript" has been kept, the others discarded.

```{r cleaning}
corpus_df <- corpus_original_df

corpus_pre_df <- corpus_df 

## ensure dates always present
corpus_df <- corpus_df |> 
  dplyr::filter(is.na(date)==FALSE) 
  
check <- assertthat::assert_that(nrow(corpus_original_df)==nrow(corpus_df), 
                        msg = "rows dropped due to missing dates")

## close dataset at end date
corpus_df <- corpus_df |> 
  dplyr::filter(date<=end_date) 

## deduplicate consistently by section order

section_order_v <- c("events/news", 
                     "visits/ru", 
                     "visits/world")

corpus_df <- tibble::tibble(section = section_order_v) |> 
  dplyr::left_join(corpus_df,
                   by = "section") 

corpus_df <- corpus_df |> 
  dplyr::distinct(date, title, text, .keep_all = TRUE)

corpus_df <- corpus_df |> 
  dplyr::select(-id) |> 
  dplyr::rowwise() |> 
  dplyr::mutate(doc_id = stringr::str_c(website_name, "_", internal_id)) |> 
  dplyr::ungroup() |> 
  dplyr::relocate(doc_id, text, internal_id) |> 
  dplyr::arrange(date, internal_id)

```


## Summary statistics

```{r results='asis'}
summary_stats_text <- stringr::str_c(
  stringr::str_c("**Dataset name**: ", website_name),
  "**Dataset description**: all items published on archive.premier.gov.ru",
  paste("**Start date**:", min(corpus_df$date)),
  paste("**End date**:", max(corpus_df$date)),
  paste("**Total items**:", scales::number(nrow(corpus_df))),
  paste("**Available columns**:", colnames(corpus_df) %>% 
          stringr::str_c(collapse = "; ")),
  paste("**License**:", "[Creative Commons Attribution 3.0 International](http://creativecommons.org/licenses/by/3.0/deed.ru)"),
  stringr::str_c("**Link for download**: [", corpus_name, "](https://github.com/giocomai/tadadit/releases/tag/", corpus_name, ")"),
  sep = "\n\n")

summary_stats_text()

```

```{r}
#| column: body
#| fig-width: 8
#| fig-height: 4.5
corpus_df |>
  mutate(year = lubridate::year(date)) |> 
  count(year) |> 
  ggplot(mapping = aes(x = year, y = n)) +
  geom_col() +
  scale_y_continuous(name = "", labels = scales::number) +
  scale_x_continuous(name = "", breaks = scales::pretty_breaks(n = 5)) +
  labs(
    title = "Number of items per year published on the Russian-language version of archive.premier.gov.ru",
    subtitle = stringr::str_c(
      "Based on ",
      scales::number(nrow(corpus_df)),
      " items published between ",
      format.Date(x = min(corpus_df$date), "%d %B %Y"), 
      " and ",
      format.Date(x = max(corpus_df$date), "%d %B %Y")),
    caption = "Source: Giorgio Comai / tadadit.xyz"
  )
```

```{r}
words_per_day_df <- corpus_df |> 
  cas_count_total_words() |> 
  mutate(date = lubridate::as_date(date),
         pattern = "total words")

words_per_day_df |> 
  cas_summarise(period = "year", auto_convert = TRUE) |>
  rename(year = date) |> 
  ggplot(mapping = aes(x = year, y = n)) +
  geom_col() +
  scale_y_continuous(name = "", labels = scales::number) +
  scale_x_continuous(name = "", breaks = scales::pretty_breaks(n = 5)) +
  labs(title = "Number of words per year published on the Russian-language version of archive.premier.gov.ru",
       subtitle = stringr::str_c("Based on ",
                                 scales::number(nrow(corpus_df)),
                                 " items published between ",
                                 format.Date(x = min(corpus_df$date), "%d %B %Y"), 
                                 " and ",
                                 format.Date(x = max(corpus_df$date), "%d %B %Y")),
       caption = "Source: Giorgio Comai / tadadit.xyz")
```



```{r piggyback, eval = FALSE}

corpus_path <- fs::path(fs::path_home_r(), 
                      "R",
                      "castarter_2024",
                      "corpora")

fs::dir_create(corpus_path)

release_file <- fs::path(corpus_path, 
                         stringr::str_c(corpus_name, ".csv.gz"))

corpus_df |> 
  readr::write_csv(file = release_file)


piggyback::pb_release_create(repo = "giocomai/tadadit",
                             tag = corpus_name,
                             body = summary_stats_text)

piggyback::pb_upload(file = release_file,
                     repo = "giocomai/tadadit",
                     tag = corpus_name)

ods_file <- fs::path(corpus_path, 
                         stringr::str_c(path = corpus_name, ".ods"))
                      
readODS::write_ods(x = corpus_df, path = ods_file)

piggyback::pb_upload(file = ods_file,
          repo = "giocomai/tadadit",
          tag = corpus_name)

cas_write_corpus(corpus = corpus_df,
                 partition = "year",
                 tif_compliant = FALSE,
                 path = fs::path(corpus_path, corpus_name))
```


